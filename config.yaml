# config.yml
llm:
  providers:
    - name: "openai"
      model: "gpt-3.5-turbo"
      api_key_env: "OPENAI_API_KEY"
    - name: "ollama"
      endpoint: "http://localhost:11434"
      model: "llama2"

monitoring:
  intervals:
    system_metrics: 5    # seconds
    llm_monitoring: 10   # seconds
    output_parsing: 2    # seconds
  
storage:
  compression_enabled: true
  archive_after_days: 7
  max_log_size_mb: 100